#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Vulnerability Analysis Agent Main Module

This module serves as the entry point for the Vulnerability Analysis Agent, responsible for:
1. Loading vulnerability scan results
2. Analyzing identified vulnerabilities 
3. Correlating them with known CVEs
4. Assessing severity and prioritizing vulnerabilities
5. Generating a comprehensive vulnerability analysis report
"""

import os
import json
import argparse
import logging
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env'))

from vulnerability_lookup import VulnerabilityLookup
from llm_interface import LLMInterface

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("vulnerability_analysis.log"),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger("vulnerability_analysis_agent")

class VulnerabilityAnalysisAgent:
    """Analyzes vulnerability scan results and correlates with CVE database"""
    
    def __init__(self, scan_results_path, output_path, api_key=None):
        """
        Initialize the Vulnerability Analysis Agent
        
        Args:
            scan_results_path (str): Path to the vulnerability scan results JSON file
            output_path (str): Path to save the analysis report JSON file
            api_key (str, optional): API key for vulnerability database access
        """
        self.scan_results_path = scan_results_path
        self.output_path = output_path
        
        # Create parent directory of output file if it doesn't exist
        output_dir = os.path.dirname(output_path)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
        
        # Initialize vulnerability lookup tool
        self.vuln_lookup = VulnerabilityLookup(api_key)
        
        # Initialize LLM Interface for enhanced analysis
        self.llm = LLMInterface()
        
        # Load scan results
        self.scan_results = self._load_scan_results()
        
        # Initialize the analysis report
        self.analysis_report = {
            "metadata": {
                "analysis_date": datetime.now().isoformat(),
                "scan_results_source": scan_results_path,
            },
            "summary": {},
            "vulnerabilities": [],
            "recommendations": []
        }

    def _load_scan_results(self):
        """Load vulnerability scan results from JSON file"""
        try:
            logger.info(f"Loading scan results from {self.scan_results_path}")
            with open(self.scan_results_path, 'r') as f:
                return json.load(f)
        except (json.JSONDecodeError, FileNotFoundError) as e:
            logger.error(f"Failed to load scan results: {str(e)}")
            raise

    def analyze_vulnerabilities(self):
        """Analyze the vulnerabilities found in scan results"""
        logger.info("Starting vulnerability analysis")
        
        # First, let LLM summarize the scan results for better context
        scan_summary = self.llm.summarize_scan_results(self.scan_results)
        self.analysis_report["summary"] = scan_summary
        
        # Extract unique vulnerabilities from scan results
        unique_vulns = self._extract_unique_vulnerabilities()
        logger.info(f"Found {len(unique_vulns)} unique vulnerabilities to analyze")
        
        # Process each vulnerability
        for vuln in unique_vulns:
            analyzed_vuln = self._analyze_single_vulnerability(vuln)
            if analyzed_vuln:
                self.analysis_report["vulnerabilities"].append(analyzed_vuln)
        
        # Sort vulnerabilities by severity (highest first)
        self.analysis_report["vulnerabilities"].sort(
            key=lambda x: float(x.get("cvss_score", 0) or 0), 
            reverse=True
        )
        
        # Generate recommendations using LLM
        self.analysis_report["recommendations"] = self.llm.generate_recommendations(
            self.analysis_report["vulnerabilities"]
        )
        
        # Save the analysis report
        self._save_analysis_report()
        
        logger.info("Vulnerability analysis completed")
        return self.analysis_report
    
    def _extract_unique_vulnerabilities(self):
        """Extract unique vulnerabilities from scan results"""
        # Implementation will depend on the structure of scan_results
        # This is a placeholder that needs to be customized based on actual data structure
        unique_vulns = []
        
        for tool_name, tool_results in self.scan_results.items():
            if isinstance(tool_results, list):
                for finding in tool_results:
                    if isinstance(finding, dict) and "description" in finding:
                        unique_vulns.append({
                            "source_tool": tool_name,
                            "description": finding["description"],
                            "raw_finding": finding
                        })
            elif isinstance(tool_results, dict):
                # Handle nested results
                for section, findings in tool_results.items():
                    if isinstance(findings, list):
                        for finding in findings:
                            if isinstance(finding, dict) and "description" in finding:
                                unique_vulns.append({
                                    "source_tool": f"{tool_name}.{section}",
                                    "description": finding["description"],
                                    "raw_finding": finding
                                })
        
        return unique_vulns
    
    def _analyze_single_vulnerability(self, vulnerability):
        """
        Analyze a single vulnerability by looking up CVE information
        
        Args:
            vulnerability (dict): Vulnerability information extracted from scan results
            
        Returns:
            dict: Analyzed vulnerability with CVE information
        """
        logger.info(f"Analyzing vulnerability: {vulnerability['description'][:50]}...")
        
        # Look up CVE information using the vulnerability description
        cve_results = self.vuln_lookup.search_vulnerability(vulnerability["description"])
        
        if not cve_results:
            # If no direct match, let LLM try to find related vulnerabilities
            logger.info("No direct CVE match, using LLM for enhanced lookup")
            cve_results = self.llm.enhance_vulnerability_lookup(vulnerability["description"])
            
        # If we have results, take the most relevant one (first in the list)
        if cve_results:
            cve_info = cve_results[0]
            
            # Prepare the analyzed vulnerability report
            analyzed_vuln = {
                "source_tool": vulnerability["source_tool"],
                "description": vulnerability["description"],
                "cve_id": cve_info.get("id", "Unknown"),
                "title": cve_info.get("title", "Unknown"),
                "published_date": cve_info.get("published", "Unknown"),
                "cvss_score": cve_info.get("cvss", {}).get("score", "Unknown"),
                "cvss_vector": cve_info.get("cvss", {}).get("vector", "Unknown"),
                "detailed_description": cve_info.get("description", ""),
                "references": cve_info.get("references", []),
                "raw_finding": vulnerability["raw_finding"]
            }
            
            # Let LLM provide additional context and mitigation advice
            additional_insights = self.llm.analyze_vulnerability(analyzed_vuln)
            analyzed_vuln.update(additional_insights)
            
            return analyzed_vuln
        
        # If no CVE match found, return original vulnerability with minimal info
        logger.warning(f"No CVE match found for vulnerability: {vulnerability['description'][:50]}...")
        return {
            "source_tool": vulnerability["source_tool"],
            "description": vulnerability["description"],
            "cve_id": "Not Found",
            "severity": "Unknown",
            "raw_finding": vulnerability["raw_finding"],
            "notes": "No matching CVE found. This may be a custom finding or a false positive."
        }
    
    def _save_analysis_report(self):
        """Save the analysis report to a JSON file"""
        logger.info(f"Saving analysis report to {self.output_path}")
        
        with open(self.output_path, 'w') as f:
            json.dump(self.analysis_report, f, indent=2)


def main():
    """Main function to run the Vulnerability Analysis Agent"""
    parser = argparse.ArgumentParser(description="Vulnerability Analysis Agent")
    parser.add_argument(
        "--scan-results",
        default="/home/kali/Desktop/Genius-Penetration/agents/vulnerability_scanner_agent/output/vuln_scan_results.json",
        help="Path to vulnerability scan results JSON file"
    )
    parser.add_argument(
        "--output-dir",
        default="/home/kali/Desktop/Genius-Penetration/agents/vulnerability_analysis_agent/output/vuln_analysis_report.json",
        help="Path to save the analysis report JSON file"
    )
    parser.add_argument(
        "--api-key",
        help="API key for vulnerability database access",
        default=None
    )
    
    args = parser.parse_args()
    
    # Create analysis agent and run analysis
    agent = VulnerabilityAnalysisAgent(
        args.scan_results, 
        args.output_dir,  # Now treated as full file path
        args.api_key
    )
    
    analysis_report = agent.analyze_vulnerabilities()
    
    # Print summary to console
    print("\n" + "=" * 80)
    print("VULNERABILITY ANALYSIS SUMMARY")
    print("=" * 80)
    
    if "vulnerabilities" in analysis_report:
        vulns = analysis_report["vulnerabilities"]
        print(f"\nFound {len(vulns)} vulnerabilities:")
        
        # Group by severity for better reporting
        high_vulns = [v for v in vulns if isinstance(v.get("cvss_score"), (int, float)) and float(v.get("cvss_score", 0)) >= 7.0]
        medium_vulns = [v for v in vulns if isinstance(v.get("cvss_score"), (int, float)) and 4.0 <= float(v.get("cvss_score", 0)) < 7.0]
        low_vulns = [v for v in vulns if isinstance(v.get("cvss_score"), (int, float)) and float(v.get("cvss_score", 0)) < 4.0]
        unknown_vulns = [v for v in vulns if not isinstance(v.get("cvss_score"), (int, float))]
        
        print(f"  - High severity: {len(high_vulns)}")
        print(f"  - Medium severity: {len(medium_vulns)}")
        print(f"  - Low severity: {len(low_vulns)}")
        print(f"  - Unknown severity: {len(unknown_vulns)}")
        
        # Show top 3 high severity vulnerabilities
        if high_vulns:
            print("\nTop high severity vulnerabilities:")
            for i, vuln in enumerate(high_vulns[:3]):
                print(f"  {i+1}. {vuln.get('cve_id', 'N/A')} - {vuln.get('title', vuln.get('description', 'Unknown')[:60])}... " +
                      f"(CVSS: {vuln.get('cvss_score', 'Unknown')})")
    
    print("\nFull analysis report saved to:", args.output_dir)
    print("=" * 80)


if __name__ == "__main__":
    main()